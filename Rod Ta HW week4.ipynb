{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rod Ta\n",
    "#9/25/17\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read Iris data set\n",
    "\n",
    "#df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\n",
    "df = pd.read_csv('iris.csv', header = None)\n",
    "df.tail()\n",
    "\n",
    "IA = df.iloc[:,:].values\n",
    "#for i_ in range(0,len(df),1):\n",
    "#    print(i_, IA[i_,:])\n",
    "\n",
    "Cl = IA[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# get Iris classifications\n",
    "\n",
    "IC = np.unique(IA[:,4])\n",
    "print (IC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa red o\n",
      "Iris-versicolor blue x\n",
      "Iris-virginica green *\n"
     ]
    }
   ],
   "source": [
    "pltC = ('red', 'blue', 'green')\n",
    "pltM = ('o', 'x', '*')\n",
    "for i in range(0,3):\n",
    "    print(IC[i], pltC[i], pltM[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length in cm\n",
      "sepal width in cm\n",
      "petal length in cm\n",
      "petal width in cm\n"
     ]
    }
   ],
   "source": [
    "# setup Iris feature lablels\n",
    "\n",
    "IrisF=(\"sepal length in cm\", \"sepal width in cm\", \"petal length in cm\", \"petal width in cm\")\n",
    "for i in range(0,4):\n",
    "    print(IrisF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdalineGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Code from \"Python Machine Learning,\" Sebastian Raschka, Packt Publishing, 2015,\n",
    "    with modifications.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "        Passes over the training dataset.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_ : list\n",
    "        Number of misclassifications in every epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self.w_ = np.zeros(1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            output = self.net_input(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\" Calculate net input \"\"\"\n",
    "        return (np.dot(X, self.w_[1:]) + self.w_[0])\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\" Compute linear activation \"\"\"\n",
    "        return self.net_input(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Return class label after unit step \"\"\"\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1) \n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\" Return accuracy of the model \"\"\"\n",
    "        return (1.0 - abs(y - self.predict(X)).sum() / (2.0 * y.size))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TwoFeatureMean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TwoFeature(iris1,iris2,feature1,feature2):\n",
    "    # focus on classification of \"virginica\" and \"versicolor\", class indexes 0 and 1; \n",
    "    # set to 1 and -1 in class array\n",
    "    cdx = np.array([iris1,iris2])   \n",
    "    # focus on using only 2 features\n",
    "    fdx = np.array([feature1,feature2])\n",
    "\n",
    "    i = 0\n",
    "    numCl = 0\n",
    "    for i in range(0 , len(Cl)):\n",
    "        if Cl[i] == IC[cdx[0]]:\n",
    "            numCl += 1\n",
    "        if Cl[i] == IC[cdx[1]]:\n",
    "            numCl += 1    \n",
    "        i += 1  \n",
    "\n",
    "    NC = np.zeros((numCl))\n",
    "    NF = np.zeros((numCl, 2))\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in range(0 , len(Cl)):\n",
    "        if Cl[i] == IC[cdx[0]]:        \n",
    "            NC[j] = 1\n",
    "            NF[j,0] = IA[i,fdx[0]]\n",
    "            NF[j,1] = IA[i,fdx[1]]\n",
    "            j += 1\n",
    "        if Cl[i] == IC[cdx[1]]:      \n",
    "            NC[j] = -1\n",
    "            NF[j,0] = IA[i,fdx[0]]\n",
    "            NF[j,1] = IA[i,fdx[1]]\n",
    "            j += 1\n",
    "        i += 1\n",
    "        \n",
    "    NF_Std = np.copy(NF)\n",
    "    NF_Std[:,0] = (NF[:,0] - NF[:,0].mean()) / NF[:,0].std()\n",
    "    NF_Std[:,1] = (NF[:,1] - NF[:,1].mean()) / NF[:,1].std()\n",
    "    \n",
    "    ada = AdalineGD(n_iter=50, eta=0.003)\n",
    "    ada.fit(NF_Std, NC)\n",
    "    \n",
    "    print (IC[iris1] + \",\" +IC[iris2] + \" \" + IrisF[feature1] + \", \"+ IrisF[feature2] + \":\") \n",
    "    print (ada.accuracy(NF_Std, NC))\n",
    "    TwoFeatureMean.append(ada.accuracy(NF_Std, NC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two Features: \n",
      "\n",
      "Iris-versicolor,Iris-virginica sepal length in cm, sepal width in cm:\n",
      "0.75\n",
      "Iris-versicolor,Iris-virginica sepal length in cm, petal length in cm:\n",
      "0.94\n",
      "Iris-versicolor,Iris-virginica sepal length in cm, petal width in cm:\n",
      "0.94\n",
      "Iris-versicolor,Iris-virginica sepal width in cm, petal length in cm:\n",
      "0.93\n",
      "Iris-versicolor,Iris-virginica sepal width in cm, petal width in cm:\n",
      "0.95\n",
      "Iris-versicolor,Iris-virginica petal length in cm, petal width in cm:\n",
      "0.94\n",
      "\n",
      "average accuracy:  0.908333333333\n"
     ]
    }
   ],
   "source": [
    "# two features\n",
    "print (\"Two Features: \\n\")\n",
    "\n",
    "TwoFeature(1,2,0,1)\n",
    "TwoFeature(1,2,0,2)\n",
    "TwoFeature(1,2,0,3)\n",
    "TwoFeature(1,2,1,2)\n",
    "TwoFeature(1,2,1,3)\n",
    "TwoFeature(1,2,2,3)\n",
    "    \n",
    "print (\"\\naverage accuracy: \", sum(TwoFeatureMean)/len(TwoFeatureMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ThreeFeatureMean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThreeFeature(iris1,iris2,feature1,feature2,feature3):\n",
    "    # focus on classification of \"virginica\" and \"versicolor\", class indexes 0 and 1; \n",
    "    # set to 1 and -1 in class array\n",
    "    cdx = np.array([iris1,iris2])   \n",
    "    # focus on using three features\n",
    "    fdx = np.array([feature1,feature2,feature3])\n",
    "\n",
    "    i = 0\n",
    "    numCl = 0\n",
    "    for i in range(0 , len(Cl)):\n",
    "        if Cl[i] == IC[cdx[0]]:\n",
    "            numCl += 1\n",
    "        if Cl[i] == IC[cdx[1]]:\n",
    "            numCl += 1    \n",
    "        i += 1  \n",
    "\n",
    "    NC = np.zeros((numCl))\n",
    "    NF = np.zeros((numCl, 3))\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in range(0 , len(Cl)):\n",
    "        if Cl[i] == IC[cdx[0]]:        \n",
    "            NC[j] = 1\n",
    "            NF[j,0] = IA[i,fdx[0]]\n",
    "            NF[j,1] = IA[i,fdx[1]]\n",
    "            NF[j,2] = IA[i,fdx[2]]\n",
    "            j += 1\n",
    "        if Cl[i] == IC[cdx[1]]:      \n",
    "            NC[j] = -1\n",
    "            NF[j,0] = IA[i,fdx[0]]\n",
    "            NF[j,1] = IA[i,fdx[1]]\n",
    "            NF[j,2] = IA[i,fdx[2]]\n",
    "            j += 1\n",
    "        i += 1\n",
    "        \n",
    "    NF_Std = np.copy(NF)\n",
    "    NF_Std[:,0] = (NF[:,0] - NF[:,0].mean()) / NF[:,0].std()\n",
    "    NF_Std[:,1] = (NF[:,1] - NF[:,1].mean()) / NF[:,1].std()\n",
    "    NF_Std[:,2] = (NF[:,2] - NF[:,2].mean()) / NF[:,2].std()\n",
    "    \n",
    "    ada = AdalineGD(n_iter=50, eta=0.003)\n",
    "    ada.fit(NF_Std, NC)\n",
    "    \n",
    "    print (IC[iris1] + \",\" +IC[iris2] + \" \" + IrisF[feature1] + \", \"+ IrisF[feature2] + \", \" + IrisF[feature3] + \":\") \n",
    "    print (ada.accuracy(NF_Std, NC))\n",
    "    ThreeFeatureMean.append(ada.accuracy(NF_Std, NC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three features: \n",
      "\n",
      "Iris-versicolor,Iris-virginica sepal length in cm, sepal width in cm, petal length in cm:\n",
      "0.93\n",
      "Iris-versicolor,Iris-virginica sepal length in cm, sepal width in cm, petal width in cm:\n",
      "0.95\n",
      "Iris-versicolor,Iris-virginica sepal length in cm, petal length in cm, petal width in cm:\n",
      "0.96\n",
      "Iris-versicolor,Iris-virginica sepal width in cm, petal length in cm, petal width in cm:\n",
      "0.96\n",
      "\n",
      "average accuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "# three features\n",
    "print (\"Three features: \\n\" )\n",
    "\n",
    "ThreeFeature(1,2,0,1,2)\n",
    "ThreeFeature(1,2,0,1,3)\n",
    "ThreeFeature(1,2,0,2,3)\n",
    "ThreeFeature(1,2,1,2,3)\n",
    "\n",
    "print (\"\\naverage accuracy: \", sum(ThreeFeatureMean)/len(ThreeFeatureMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FourFeatureMean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FourFeature(iris1,iris2,feature1,feature2,feature3,feature4):\n",
    "    # focus on classification of \"virginica\" and \"versicolor\", class indexes 0 and 1; \n",
    "    # set to 1 and -1 in class array\n",
    "    cdx = np.array([iris1,iris2])   \n",
    "    # focus on using all 4 features\n",
    "    fdx = np.array([feature1,feature2,feature3,feature4])\n",
    "\n",
    "    i = 0\n",
    "    numCl = 0\n",
    "    for i in range(0 , len(Cl)):\n",
    "        if Cl[i] == IC[cdx[0]]:\n",
    "            numCl += 1\n",
    "        if Cl[i] == IC[cdx[1]]:\n",
    "            numCl += 1    \n",
    "        i += 1  \n",
    "\n",
    "    NC = np.zeros((numCl))\n",
    "    NF = np.zeros((numCl, 4))\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for i in range(0 , len(Cl)):\n",
    "        if Cl[i] == IC[cdx[0]]:        \n",
    "            NC[j] = 1\n",
    "            NF[j,0] = IA[i,fdx[0]]\n",
    "            NF[j,1] = IA[i,fdx[1]]\n",
    "            NF[j,2] = IA[i,fdx[2]]\n",
    "            NF[j,3] = IA[i,fdx[3]]\n",
    "            j += 1\n",
    "        if Cl[i] == IC[cdx[1]]:      \n",
    "            NC[j] = -1\n",
    "            NF[j,0] = IA[i,fdx[0]]\n",
    "            NF[j,1] = IA[i,fdx[1]]\n",
    "            NF[j,2] = IA[i,fdx[2]]\n",
    "            NF[j,3] = IA[i,fdx[3]]\n",
    "            j += 1\n",
    "        i += 1\n",
    "        \n",
    "    NF_Std = np.copy(NF)\n",
    "    NF_Std[:,0] = (NF[:,0] - NF[:,0].mean()) / NF[:,0].std()\n",
    "    NF_Std[:,1] = (NF[:,1] - NF[:,1].mean()) / NF[:,1].std()\n",
    "    NF_Std[:,2] = (NF[:,2] - NF[:,2].mean()) / NF[:,2].std()\n",
    "    NF_Std[:,3] = (NF[:,3] - NF[:,3].mean()) / NF[:,3].std()\n",
    "    \n",
    "    ada = AdalineGD(n_iter=50, eta=0.003)\n",
    "    ada.fit(NF_Std, NC)\n",
    "    \n",
    "    print (IC[iris1] + \",\" +IC[iris2] + \" \" + IrisF[feature1] + \", \"+ IrisF[feature2] + \", \" + IrisF[feature3] + \", \" + IrisF[feature4] + \":\") \n",
    "    print (ada.accuracy(NF_Std, NC))\n",
    "    FourFeatureMean.append(ada.accuracy(NF_Std, NC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-versicolor,Iris-virginica sepal length in cm, sepal width in cm, petal length in cm, petal width in cm:\n",
      "0.97\n",
      "\n",
      "average accuracy:  0.97\n"
     ]
    }
   ],
   "source": [
    "#Four features\n",
    "FourFeature(1,2,0,1,2,3)\n",
    "print (\"\\naverage accuracy: \", sum(FourFeatureMean)/len(FourFeatureMean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe best accuracy I was able to achieve from the 11 classes is the class using all 4 features\\nat once\\n\\nIn the case of using two features at a time:\\n    -Highest accruacy obtained: 0.95\\n    -Average accuracy: 0.908333333333\\n    \\nIn the case of using three features at a time:\\n    -Highest accruacy obtained: 0.96\\n    -Average accuracy: 0.95\\n    \\nIn the case of using four features at a time:\\n    -Highest accuracy obtained: 0.97\\n    -Average accuracy: 0.97 \\n\\nThrough my findings mentioned above, using more dimensions definitely helps when tying to\\nclassify the data in this dataset. There is a strong correlation with the increase in accuracy\\nand the use of more dimensions.\\n'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The best accuracy I was able to achieve from the 11 classes is the class using all 4 features\n",
    "at once\n",
    "\n",
    "In the case of using two features at a time:\n",
    "    -Highest accruacy obtained: 0.95\n",
    "    -Average accuracy: 0.908333333333\n",
    "    \n",
    "In the case of using three features at a time:\n",
    "    -Highest accruacy obtained: 0.96\n",
    "    -Average accuracy: 0.95\n",
    "    \n",
    "In the case of using four features at a time:\n",
    "    -Highest accuracy obtained: 0.97\n",
    "    -Average accuracy: 0.97 \n",
    "\n",
    "Through my findings mentioned above, using more dimensions definitely helps when tying to\n",
    "classify the data in this dataset. There is a strong correlation with the increase in accuracy\n",
    "and the use of more dimensions.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
