{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rod Ta\n",
    "#10/30/17\n",
    "#Week 9 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from astropy.table import Table, Column\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\n",
    "\n",
    "iris.tail()\n",
    "\n",
    "#samples\n",
    "X = iris.iloc[:,0:4].values\n",
    "ITemp = iris.iloc[:,4:5].values\n",
    "\n",
    "for i in range (0,150):\n",
    "    if ITemp[i] == 'Iris-setosa':\n",
    "        ITemp[i] = 0\n",
    "    elif ITemp[i] == 'Iris-versicolor':\n",
    "        ITemp[i] = 1\n",
    "    else:\n",
    "        ITemp[i] = 2\n",
    "        \n",
    "y = []\n",
    "\n",
    "for i in range (0,150):\n",
    "    y.append(ITemp[i][0])\n",
    "      \n",
    "#classification\n",
    "y = np.asarray(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 50% training data and 50% test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,y, test_size=0.50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(estimator,depth):\n",
    "    forest = RandomForestClassifier(criterion='entropy',\n",
    "                                n_estimators=estimator,\n",
    "                                max_depth=depth,\n",
    "                                oob_score = True)\n",
    "\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    #print (forest.predict(X))\n",
    "    oobScore = forest.oob_score_\n",
    "    #print (oobScore)\n",
    "    #print (forest.score(X,y))\n",
    "    return oobScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTree = np.zeros(3)\n",
    "numTree[0] = 15\n",
    "numTree[1] = 50\n",
    "numTree[2] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Display_OOBScore(depth):\n",
    "    score = np.zeros(3)\n",
    "    score[0] = RandomForest(15,depth)\n",
    "    score[1] = RandomForest(50,depth)\n",
    "    score[2] = RandomForest(100,depth)\n",
    "\n",
    "    oob = Table([numTree[:],score[:]],\n",
    "                names = ('Number of Trees','out-of-bag score'))\n",
    "    print(\"out-of-bag score for depth of \",depth)\n",
    "    return oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out-of-bag score for depth of  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;Table length=3&gt;\n",
       "<table id=\"table4593156952\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Number of Trees</th><th>out-of-bag score</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>15.0</td><td>0.733333333333</td></tr>\n",
       "<tr><td>50.0</td><td>0.746666666667</td></tr>\n",
       "<tr><td>100.0</td><td>0.76</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "Number of Trees out-of-bag score\n",
       "    float64         float64     \n",
       "--------------- ----------------\n",
       "           15.0   0.733333333333\n",
       "           50.0   0.746666666667\n",
       "          100.0             0.76"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Display_OOBScore(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out-of-bag score for depth of  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;Table length=3&gt;\n",
       "<table id=\"table4657599488\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Number of Trees</th><th>out-of-bag score</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>15.0</td><td>0.933333333333</td></tr>\n",
       "<tr><td>50.0</td><td>0.946666666667</td></tr>\n",
       "<tr><td>100.0</td><td>0.946666666667</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "Number of Trees out-of-bag score\n",
       "    float64         float64     \n",
       "--------------- ----------------\n",
       "           15.0   0.933333333333\n",
       "           50.0   0.946666666667\n",
       "          100.0   0.946666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Display_OOBScore(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out-of-bag score for depth of  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "&lt;Table length=3&gt;\n",
       "<table id=\"table4657523960\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Number of Trees</th><th>out-of-bag score</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>15.0</td><td>0.933333333333</td></tr>\n",
       "<tr><td>50.0</td><td>0.933333333333</td></tr>\n",
       "<tr><td>100.0</td><td>0.96</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "Number of Trees out-of-bag score\n",
       "    float64         float64     \n",
       "--------------- ----------------\n",
       "           15.0   0.933333333333\n",
       "           50.0   0.933333333333\n",
       "          100.0             0.96"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Display_OOBScore(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nI created 3 tables above with 3 different simulations\\n\\nFor each simulations, I used 3 different number of trees: 15,50 and 100\\nI also use 3 different depth for each the tables: depth of 1, depth of 2 and depth of 3.\\n\\nTABLE 1:\\nTable 1 simulation is ran with the decision tree having a depth of 1, the out of bag score for the different \\nnumber of trees hovers in the range of 0.74 to 0.77\\n\\nTABLE 2:\\nTable 2 simulation is ran with the decision tree having a depth of 2. The out of bag score is high, ranging from\\n0.93 to 0.96\\n\\nTABLE 3:\\nTable 3 simulation is ran with the decision tree having a depth of 3. The out of bag score is also very high ranging \\nfrom 0.93 to 0.946\\n\\nIn summary, I noticed that using decision trees with depth of 2 and 3 both have higher out of bag score than when\\nusing decision trees with depth of 1. However, there seems to be not much of a difference in out of bag scores when \\nusing decision trees with depth of 2 and 3.\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "I created 3 tables above with 3 different simulations\n",
    "\n",
    "For each simulations, I used 3 different number of trees: 15,50 and 100\n",
    "I also use 3 different depths for each of the tables: depth of 1, depth of 2 and depth of 3.\n",
    "\n",
    "TABLE 1:\n",
    "Table 1 simulation is ran with the decision tree having a depth of 1, the out of bag score for the different \n",
    "number of trees hovers in the range of 0.73 to 0.76\n",
    "\n",
    "TABLE 2:\n",
    "Table 2 simulation is ran with the decision tree having a depth of 2. The out of bag score for each of\n",
    "the 3 different number of trees is high, ranging from 0.93 to 0.94\n",
    "\n",
    "TABLE 3:\n",
    "Table 3 simulation is ran with the decision tree having a depth of 3. The out of bag score for each of\n",
    "the 3 different number of trees is also very high ranging from 0.93 to 0.96\n",
    "\n",
    "I noticed that using decision trees with depth of 2 and 3 both have higher out of bag score than when\n",
    "using decision trees with depth of 1. However, there seems to be not much of a difference in out of bag scores between \n",
    "decision trees with depth of 2 and 3.\n",
    "\n",
    "Changing the number of trees does not seem to affect the out of bag score too much\n",
    "\n",
    "In summary, changing the depth causes a greater change in out of bag score than when changing the number of trees.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
